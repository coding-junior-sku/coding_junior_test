1.django와 spring boot를 쓴 이유는 무엇이냐?
1.답
처음에는 kobert를 이용해 파인튜닝을 하려고 했었지만 최대 2문장, 512토큰을 이용하므로 뉴스기사의 축약에는 쓸 수가 없었습니다.
그래서 kobertsum 깃허브 라이브러리를 파이썬 가상환경에 설치해서 파인튜닝을 진행하려고 하였지만 결국 실패했습니다.
원래 의도는 파인튜닝한 모델을 부르기 위해 파이썬을 사용하는데 그에 대한 개발 프레임워크로 django를 사용한 것입니다. 
spring boot에서 파이썬을 쓰기위해서는 라이브러리를 따로 설치해야하는데 잘 안되고 불편할 확률이 높습니다.
비록 실패하였지만, 원래 계획했던대로 django를 사용하기로 하고, 네이버 clova 서버에게 요청을 보내고 받는 파이썬 코드를 작성하였습니다
spring boot는 그전에도, 이번 교육때도 가장 많이 공부한 프레임 워크라 spring boot를 데이터베이스에 연결하는 방법도 익숙하여서 메인으로 하여 웹을 만들었습니다.


2.spring boot에서는 어떻게 django에게 데이터를 넘겨주지?
2.답
RestTemplate 클래스의 postForObject라는 함수를 사용하여 HttpEntity클래스로  json 형식의 데이터와 헤더정보를 합쳐서 post방식으로 넘겨줍니다.
구글의 gson 라이브러리를 임포트하여 JsonObject와 JsonArray 클래스를 사용합니다. JsonObject의 addProperty 함수를 이용하여 키이름을 지어주고 원하는데이터를 넣어 json형태의 데이터로 만들어줍니다. 데이터들을 모은 배열 형태로 보내고 싶다면 JsonArray 클래스의 add를 이용하여 JsonObject들을 넣어줍니다.
HttpHeaders 클래스를 이용하여 MediaType.APPLICATION_JSON을 세팅하여 보낼 데이터가 json이라는 것을 명시합니다.
HttpEntity클래스를 이용하여 json형식의 데이터와 헤더정보를 합쳐서 RestTemplate의 postForObject 함수 매개변수로 넣어줍니다.


3.spring boot에서는 어떻게 django에게 데이터를 받지?
3.답
RestTemplate 클래스의 postForObject라는 함수의 리턴값이 요청한 서버로부터 받은 데이터입니다.
django에서도 데이터를 json 형식으로 반환합니다. 정확히 말하면 데이터가 json형식인 문자열입니다.
구글의 gson라이브러리의 JsonObject와 JsonArray, JsonElement,JsonParser 클래스를 사용합니다.
데이터가 json형식인 문자열을 JsonParser의 parseString을 이용해 JsonElement객체를 얻습니다. JsonElement는 JsonObject, JsonArray의 상위 개념입니다.
JsonElement 클래스의 getAsJsonArray()함수를 이용하여 JsonArray 객체를 얻습니다.
JsonArray에서 순차적으로 배열을 돌면서 JsonElement 객체를 하나씩 얻습니다.
getAsJsonObject()로 JsonObject를 얻습니다.
JsonObject객체에서 get~(키이름) 형태로 키의 값을 얻습니다. getAsString()함수를 통해 키의 값을 문자열형태로 파싱해줍니다.


4. django에서는 어떻게 spring boot에게 데이터를 받지?
4.답
urls.py에 선언된 url에 연결된 views.py의 함수의 매개변수를 통해 request를 받습니다
post형식의 데이터는 request.body에 실려서 옵니다
이 json형식의 데이터 문자열을 파싱하기 위해, json 모듈의 loads()함수를 씁니다. 그러면 파이썬 딕셔너리의 형태가 됩니다.
받은 데이터가 배열이면 반복문을 돌면서 데이터객체 하나를 꺼내고
원하는 키의 값을 얻기 위해, 파이썬 딕셔너리의 형태로 키의 이름을 넣어서 가져 올 수 있습니다.



5.django에서는 어떻게 spring boot에게 데이터를 넘겨주지?
5.답
JsonResponse모듈을 이용해서 python 딕셔너리를 매개변수로 받아 JSON응답을 만듭니다.
하지만 여기서 돌려줄 데이터는 뉴스 요약 기사들이므로 배열 형태입니다. 이럴때는 safe파라미터의 값을 False로 합니다.


6.django에서는 어떻게 naver clova에게 데이터를 넘겨주지?
6.답
보내고자 하는 데이터를 naver clova summary  api가 원하는데로, 딕셔너리 형태를 만듭니다
이 딕셔너리를 json 문자열 형태로 바꿔서 보내야하기 때문에 json 모듈의 dumps 함수를 이용합니다
또한 naver clova summary api가 원하는데로, 헤더도 딕셔너리 형태로 만듭니다.
requests 모듈의 post함수를 써서 post 방식으로  url,json 모듈의 dumps함수로 변환한 데이터와 헤더를 넣어서 요청합니다.

7.django에서는 어떻게 naver clova에게 데이터를 받지?
request모듈의 post 함수가 리턴하는 Response객체로 받습니다.
하지는 이 Response객체에는 상태 코드가 포함되어 있으며, 순수 본격 데이터만 받으려면 .text로 접근해야합니다.
json 문자열 형태를 파이썬 딕셔너리로 변환하기위해서 json 모듈의 loads함수를 사용합니다.
원하고자 하는 키의 값을 꺼내기 위해  파이썬 딕셔너리의 형태로 키의 이름을 넣어서 가져 올 수 있습니다.



8. 크롤링 코드에서 async await 쓴 이유가 뭐지?
8.답
크롤링 코드는 해당 태그를 찾아서 태그의 값을 읽어옵니다.
하지만 여러개의 정보를 가져오기 위해 태그를 찾고 값을 읽어오는 일을 여러개 해야하는데, 한태그 찾고 값을 읽어오는 일을 끝마치기 전에 다음 태그를 찾는 코드로 넘어가기도 하고 또는 태그들을 읽는 코드를 빠른 속도로 지나치기도 합니다. 따라서 태그와 값이 있는데도 크롤링을 못하는 일들이 일어나기 때문에 async await 키워드로 한 태그를 찾아서 값을 읽을때까지 그다음 코드 실행을 중단한 상태로 기다립니다.


9.크롤링을 해서 데이터베이스에 어떻게 적재를 했지?
9.답
csv의 날짜형태는 엑셀이 자신이 맘대로 바꾸기 때문에 그대로 csv값을 넣을경우 db컬럼 데이터형태와 맞지 않아 pandas로 변환해야합니다.
pandas로 변환하면 애초에 크롤링해서 원하는 형식으로 변환했던 그 형태로 자동바꿈이 됩니다.
먼저 크롤링해서 저장한 csv 파일을 pandas의 read_csv를 통해 pandas 형태로 변환하면서 읽습니다.
pymysql모듈의 connect함수를 이용하여 데이터베이스 연결 객체를 생성합니다.
데이터베이스 연결객체에서 cursor함수를 사용하여 sql을 실행하는 execute함수를 실행할 수 있는 객체를 꺼냅니다.
pandas의 iloc함수를 통해 한 행을 뽑아내고 그 행에서 컬럼이름으로 데이터들을 뽑습니다.
뽑은 데이터들을 이용해 insert sql구문을 만듭니다.
그다음 cursor함수를 사용해서 만든 객체에 execute함수를 실행하여 sql을 실행합니다
그다음에 데이터베이스 연결 객체에서 commit 함수를 사용하여 db에 commit 반영을 합니다


10.키워드를 가지고 데이터베이스에서 어떻게 기사를 뽑아냈지?(sql)
10.답
키워드를 포함되어 있는 뉴스 제목을 검색하기 때문에 where절에  like 구문을 씁니다.
날짜 최신순을 뽑아야하는데 날짜가 최신일 수록 값이 큽니다. 따라서 내림차순을 해야합니다.order by desc를 사용합니다.
3개를 뽑아야 하므로 mysql 에서 limit를 씁니다.



11.페이징 처리의 핵심 원리가 뭐지?
먼저 한페이지당 몇개의 글을 보여줄 것인지 정해야합니다.이를 amount라 합니다. 보고자하는 페이지를 page라고 합니다.
mysql에서는 첫번째 게시글 인덱스가 0부터 시작합니다.
db에서 뽑아올 게시글 인덱스 시작을 startIndex라 하면, 보고자하는 페이지에서 -1을 뺀값에서 amount를 곱합니다.
이것을 mysql sql limit startIndex amount로 구합니다.
그다음에 한화면에 페이지 버튼들을 정해진 갯수만큼 보여주는 알고리즘은 다음과 같습니다.
예를들어 한화면에 페이지 버튼을 몇개씩 보여줄것인지 결정하는 pageCount가 10이고 10단위를 블록단위라고 합시다.
 11페이지는 11/10=1.1이고 따지고보면 2번째 블록단위에 속합니다
마지막 페이지버튼 인덱스는 page를 pageCount로 나눈 실수값에 올림을 취하고 pageCount를 곱합니다
첫번째 페이지버튼 인덱스는 마지막 페이지 인덱스에서 pageCount를 빼고  +1을 더합니다.
마지막 페이지버튼 인덱스는 page의 블록단위를 따져서 구하는것이므로 실제 게시글의 갯수를 고려한 전체 마지막 페이지버튼 인덱스와 다릅니다.
화면에 출력할때 전체 마지막 페이지버튼 인덱스를 넘었는데 표시하는 일은 없어야합니다.
전체 마지막 페이지버튼 인덱스는 글 전체개수를 amount로 나누고 올림을 합니다.
따라서 마지막 페이지버튼 인덱스가 전체페이지 인덱스보다 크면 마지막 페이지버튼 인덱스를 전체페이지 인덱스 값과 같게 합니다. 
 또 경우의 수를 따져서 전체페이지 인덱스가 0이면(게시글이 0개) 마지막 페이지버튼 인덱스를 1로 수정합니다
다음 페이지블록이 존재하는가, 이전 페이지블록이 존재하는가를 따져서 1페이지부터 전체 마지막 페이지버튼 인덱스까지 자유롭게 오갈 수 있어야합니다
첫번째 버튼 인덱스가  1보다 크면, 이전 페이지블록은 존재합니다.
마지막 페이지버튼 인덱스가 전체 페이지 인덱스보다 작으면, 다음 페이지 블록은 존재합니다.



12.로그인의 핵심 원리가 뭐지?
12.답
아이디와 비밀번호를 넘겨받아 sql에서 아이디와 비밀번호가 일치하는 회원 dto를 넘겨받습니다.
회원 dto가 존재하면 로그인이 성공했다는 뜻입니다.
spring boot에서는 HttpSession이라는 값이 있습니다. 따로 계속 넘겨주는 데이터없이 페이지를 이동하더라도 서버에서 관리할 수 있는 값입니다.
회원 dto가 존재하면 HttpSession에 setAttribute를 하여 키 이름을 짓고 회원을 구분할수있는 unique한 값인 primary key를 넣습니다.
그 이후로 로그인을 한 여부나 접속한 회원이 누구인지 검사를 할때 HttpSession에서 getAttribute를 해서 primary key값을 얻어 비교합니다.



13.네이버 클로바를 쓴 이유가 뭐지?
13.답:처음에는 seq2seq함수를 이용해서  Kaggle사이트에 있는 bbc news summary 5000개의 영문 뉴스원본과 뉴스요약 데이터를 가지고 학습을 진행 했지만 테스트가 똑같은 문장이 반복되는 등 오류가 만족스런 결과가 나오지 않았습니다. 그래서 사전 학습된 트랜스포머의 디코더를 장착한 GPT‑2 나 BERT 같은 모델에 파인튜닝을 하여 추가학습을 하는 방법을 시도해야겠다는 생각을 하였고, 영문보다는 한글로 학습된 모델을 선택하려고 해서 SKT에서 만든 koBert을 학습하고 적용하려 했지만 한 번에 두 문장 정도인 512토큰 제한이 있다는 것을 알게 되었고, 카톡대화 요약으로서는 충분하지만 비교적 긴 문장인 뉴스원문 한테는 적용할 수 없었습니다. 그래서 토큰 수에 자유로운 kobertsum 모델을 하기로 했습니다. kobertsum 역시 파이썬 버전 문제와 윈도우에서 mecab적용이 잘 안되는 등 여러 문제로 선택할 수 없게 되었습니다.  그래서 openai api를 활용해서 한글 문서요약 jsonl 파일을 파인튜닝하여  테스트를 해봤으나 요약이 중간에 끊기거나 영어로 요약되는 등 여러 문제가 있어 선택할 수 없었습니다. 그래서 다른 api를 찾아보던 중 네이버 클라우드 클로버 문서요약 api를 알게 되었고 한국에서 만든 api라 한글문서 요약의 오류가 없을거 같았고 한 달에 1000번 문서요약이 무료로 이용할 수 있고 테스트 결과 만족스러운 문서요약결과를 얻게 되어 선택하게 되었습니다. 

14.매일매일 자동적재의 원리가 뭐지?
윈도우 스케줄링을 실행합니다. .ipynb 파일이 아닌 .py 파일이 동작됩니다. .py파일은 크롤링을 담당해서 csv로 만드는 역할, csv를 읽어서 pymysql로 mysql db에 insert하는 역할로 나뉘어져서 원하는 영역당 2개의 .py 파일을 등록해야합니다. .py파일을 수행시키는 파이썬 가상환경 경로 , .py파일 이름, .py파일이 있는경로(시작부터 .py파일이름 전까지)를 윈도우 스케줄러에 입력해서 태스크를 등록합니다. 즉 배터리 절약모드같은 특수한 상황이 아니면, 정해진 시간마다 .py 파일이 실행됩니다.즉 매일 크롤링하여 db에 적재하게 되는것입니다.

15.댓글이 페이지이동없이 삽입 삭제 수정이 되는 원리가 뭐지?
15.답
ajax를 이용합니다. 
즉 웹페이지를 리로드 하지 않고 데이터를 불러오는 방식입니다.
웹페이지를 리로드하면서 불필요한 리소스가 낭비가 되는데, 비동기 방식을 이용하면 필요한 데이터만 불러오면서
리소스 낭비를 줄일 수 있습니다.
자바스크립트를 쓰는 클라이언트단에서 json.strigify를 이용해서 자바스크립트 객체를 json문자열화 해서 서버단인 restcontroller로 보냅니다.
restcontroller 에서는 @RequestBody로 자바객체로 변환하여 데이터를 처리합니다.
restcontroller에서는 @ResponseBody로 자바객체를 json으로 바꿔서 보냅니다.
그 값을 클라이언트에서 ajax 통신 결과로 받고 파싱을 안하더라도 자바스크립트 객체로 바로 쓸 수 있습니다.
그렇게 ajax로 삽입삭제 수정에 관한 데이터를 보내 서버단에서 db에 반영하고, ajax 통신이 성공하면 그 결과를 자바스크립트로 처리해서 html로 동적으로 나타냅니다.


16.사용자에 따라 작성한 글의 삭제 수정 버튼이 보일지 말지 결정하는 원리가 뭐지?
16.답
로그인을 하면 spring boot에서 HttpSession에 setAttribute로 키이름을 임의로 지어주고 회원을 구분할수있는 primary id값을 넣습니다.
db에서 게시글 테이블에는 작성자 칼럼이 있는데 여기에도 회원을 구분할 수 있는 primary id값이 있습니다.
따라서 클라이언트단에서 db에서 가져온 작성자 값과 현재 로그인한 사용자값을 jstl 변수로 받아서 비교합니다. jstl에서는 ${sessionScope}로 세션값에 접근합니다.


17.채팅을 저장하고 보여주는 원리가 뭐지?
17.답
핵심은 채팅내용을 클라이언트단에서 자바스크립트로 동적으로 html을 생성하여 보이게 해주면서 db에 채팅내용을 저장해서 다음번에도 채팅페이지로 들어왔을때 db에서 지금까지한 채팅내용을 불러와서 볼수있게 해야합니다. 챗봇답변은 db에서 뉴스검색을 하고 django랑 통신해서 naverclova와 통신해서 생성하므로 서버단에서 생성을 합니다. 서버단에서 db에 접근하기 쉬우므로 챗봇답변을 생성하면 바로 db에 넣고 클라이언트 단으로 데이터를 전달하여 자바스크립트로 동적으로 html 생성하는것을 반대로 마지막에 합니다.
사용자가 뉴스 키워드를 치면 바로 자바스크립트로 사용자가 친 말풍선 스타일을 나타내주는 css 적용한 html 태그를 동적으로 생성해 원래있던 html에 append 합니다.
ajax로 사용자가 친 뉴스 키워드를 chatDto에 속하는 writeContent 키이름을 가진 json으로 보내 chatDto와 매핑을 시킵니다. 멤버 primary id로 채팅방을 구분하므로 chatdto에 세션에서 로그인한 정보를 얻어 넣어줍니다. 사람이 쓴글이면 html에서 말풍선을 오른쪽으로 위치하도록 하고 챗봇의 답변이면 말풍선을 왼쪽으로 위치하도록 구분해야합니다. 따라서 사람이 쓴글이라는 정보도 chatDTO에 넣어줍니다. 그리고 chatService.insertChat(chatDTO)로 db chats 테이블에 넣어줍니다.
그다음에 django랑 통신해서 요약한 결과인 요약뉴스리스트들을 newsSummaryDTOList에 저장합니다. 반복문을 돌기전 새로운 chatdto를 생성하여 채팅방을 구분해주는 현재 로그인한 유저의 primary id를 세션에서 꺼내 넣어줍니다. 그리고 챗봇의 답변이라는 정보 0값도 넣어줍니다.이 arraylist를 반복문으로 돌면서 newsSummaryDTO의 멤버변수들의 값을 꺼내면서 챗봇답변 string을 만듭니다. 뉴스기사3개를 요약하는것이므로 챗봇의 답변을 뉴스기사 1개씩 한다고 하면 반복문안에서 chatdto에서 채팅내용을 나타내는 writeContent를 갱신하면서 db에 넣는것을 반복합니다. 그리고 newsSummaryDtoList를 ajax success 결과값으로 보내서 동적으로 html태그를 생성해 원래 있던 html태그에 append 합니다.


18.사용한 버전 종류가 뭐지?
18.답
jdk 17를 사용했습니다.
 python 가상환경 3.9를 pycharm에 연결해서 django 구축했고, 크롤링과 윈도우 스케줄링 적재도 python가상환경 3.9에서 하였습니다.


19.윈도우 스케줄러 생각하게 된 이유가 무었인가?
답: 뉴스 키워드를 입력할 때 마다 크롤링 코드를 돌리면 실시간 최신 뉴스를 불러올 수 있지만 시간이 많이 오래걸린다는 단점이 있고, 미리 뉴스원문을 데이터베이스에 적재를 하면 빠른시간안에 뉴스원문을 불러올 수 있지만 시간이 지날 수록 오래된 뉴스가 되는 거라서 매일 최신뉴스를 자동으로 데이터베이스를 적재 해야겠다고 생각하게 되었고 구글링을 해본 결과 윈도우 스케줄러를 이용하면 할 수 있겠다고 생각했습니다.

20.원래 주제가 nlp를 이용한 자연어 챗봇인데 문서요약으로 정한 이유가 있나?
21. 토론장이라는 게시판을 만들었는데 문서요약과 어떠한 연관성을 가지는가?
22. 토론장을 어떤식으로 활용할 예정인가?
23.웹 첫 화면이  챗GPT 화면과 유사한데 참고한 이유가 있나?
24.데이터베이스 구조도에 대해 설명해 줄 수 있나?
25.Django로 네이버 클로바 모델과 스프링을 연결해줄 생각을 어떻게 하였나?
26.오브젠 멘토가 어떠한 피드백과 조언을 해주었는가?
27. 팀프로젝트를 하면서 어떠한 것을 배웠는가?
28.색을 아이보리색과 핑크색으로 한 이유가 있나?
29.향후 이 프로젝트때 만든 웹을 추가적으로 이어서 하게 된다면 어떤한 기능을 추가 하고 싶나?